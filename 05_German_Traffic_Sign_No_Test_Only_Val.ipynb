{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_German_Traffic_Sign.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# German Trafic Sign Detection using Tensorflow"
      ],
      "metadata": {
        "id": "ssoosStte44k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5nAY-P-eqoR",
        "outputId": "c76d5376-762d-48fb-ae91-e8de5c5ef449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Expecting value: line 1 column 1 (char 0)\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = ''\n",
        "os.environ['KAGGLE_KEY'] = ''\n",
        "api_token = {\"username\":\"\",\"key\":\"\"}\n",
        "\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list -s \"German Traffic Sign Recognition\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0ly4hejgjE_",
        "outputId": "e6070d27-b960-49b4-f63e-84c281948d02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                                         title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign                     GTSRB - German Traffic Sign Recognition Benchmark  612MB  2018-11-25 18:12:34          51865        789  0.8235294        \n",
            "datasets/valentynsichkar/traffic-signs-preprocessed                         Traffic Signs Preprocessed                           4GB  2019-08-31 18:22:11           7618        220  1.0              \n",
            "datasets/eunjurho/german-traffic-sign-recognition-benchmark-cropped         german_traffic_sign_recognition_benchmark_cropped  206MB  2019-11-10 15:22:13            258          6  0.75             \n",
            "datasets/bhavinmoriya/german-traffic-sign-recognition-benchmark             German Traffic Sign Recognition Benchmark          306MB  2021-12-17 17:03:58              7          3  0.3529412        \n",
            "datasets/safabouguezzi/german-traffic-sign-detection-benchmark-gtsdb        GTSDB - German Traffic Sign Detection Benchmark      2GB  2020-11-20 11:21:11            643          9  0.5625           \n",
            "datasets/valentynsichkar/traffic-signs-1-million-images-for-classification  Traffic Signs 1 million images for Classification   20GB  2021-02-08 16:45:43            195          5  1.0              \n",
            "datasets/valentynsichkar/preprocessed-light-version-of-traffic-signs        Pre-processed Light version of Traffic Signs         8GB  2021-04-10 13:35:24             34          2  1.0              \n",
            "datasets/stav42/dataset-bosch                                               dataset_bosch                                      118MB  2021-03-03 04:58:47             17          0  0.23529412       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d \"meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd90MBudgruQ",
        "outputId": "864ee436-df69-4bac-de84-fc5a677cf35e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gtsrb-german-traffic-sign.zip to /content\n",
            "100% 610M/612M [00:04<00:00, 146MB/s]\n",
            "100% 612M/612M [00:04<00:00, 137MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/gtsrb-german-traffic-sign.zip' -d '/content/dataset/'"
      ],
      "metadata": {
        "id": "7RorGyC7g6Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This command won't be needed all the time. \n",
        "# There were some extra copied folder after the unzip operation. That is why this command is used \n",
        "# to delete those \"same\" folder\n",
        "\n",
        "#!rm -rf '/content/dataset/meta'\n",
        "#!rm -rf '/content/dataset/train'\n",
        "#!rm -rf '/content/dataset/test'"
      ],
      "metadata": {
        "id": "7hV7nJ-8h4-t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset provides data for train and test\n",
        "### But the training folder needs to be converted into training and validation."
      ],
      "metadata": {
        "id": "NGx9zw0ykB_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "def split_data(path_to_data, path_to_train, path_to_val, split_size=0.1):\n",
        "\n",
        "  # Provides all folder names from a path\n",
        "  folders = os.listdir(path_to_data)\n",
        "\n",
        "  for folder in folders:\n",
        "    full_path = os.path.join(path_to_data, folder)\n",
        "    image_path = glob.glob(os.path.join(full_path, '*.png'))\n",
        "\n",
        "    x_train, x_val = train_test_split(image_path, test_size=split_size)\n",
        "\n",
        "    for x in x_train:\n",
        "      basename = os.path.basename(x)\n",
        "      path_to_folder = os.path.join(path_to_train, folder)\n",
        "\n",
        "      if not os.path.isdir(path_to_folder):\n",
        "        os.makedirs(path_to_folder)\n",
        "      \n",
        "      shutil.copy(x, path_to_folder)\n",
        "\n",
        "    for x in x_val:\n",
        "      basename = os.path.basename(x)\n",
        "      path_to_folder = os.path.join(path_to_val, folder)\n",
        "\n",
        "      if not os.path.isdir(path_to_folder):\n",
        "        os.makedirs(path_to_folder)\n",
        "      \n",
        "      shutil.copy(x, path_to_folder)\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "sSvzaf0TiXLk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_data = '/content/dataset/Train'\n",
        "path_to_train = '/content/dataset/training_data_split/train'\n",
        "path_to_val = '/content/dataset/training_data_split/val'"
      ],
      "metadata": {
        "id": "PZ2tExKSFMA4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_data(path_to_data=path_to_data, path_to_train=path_to_train, path_to_val=path_to_val)"
      ],
      "metadata": {
        "id": "x8M06IpPFuTS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time to rearrange Test set"
      ],
      "metadata": {
        "id": "KyKWCiMQHyBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def order_test_set(path_to_images, path_to_csv):\n",
        "\n",
        "    try:\n",
        "        with open(path_to_csv, 'r') as csvfile:\n",
        "\n",
        "            reader = csv.reader(csvfile, delimiter=',')\n",
        "\n",
        "            for i, row in enumerate(reader):\n",
        "\n",
        "                if i==0:\n",
        "                    continue\n",
        "\n",
        "                img_name = row[-1].replace('Test/', '')\n",
        "                label = row[-2]\n",
        "\n",
        "                path_to_folder = os.path.join(path_to_images, label)\n",
        "\n",
        "                if not os.path.isdir(path_to_folder):\n",
        "                    os.makedirs(path_to_folder)\n",
        "\n",
        "                img_full_path = os.path.join(path_to_images, img_name)\n",
        "                shutil.move(img_full_path, path_to_folder)\n",
        "\n",
        "    except:\n",
        "        print('[INFO] : Error reading csv file')\n"
      ],
      "metadata": {
        "id": "t3e-D0kfH2a4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_images = '/content/dataset/Test'\n",
        "path_to_csv = '/content/dataset/Test.csv'\n",
        "\n",
        "order_test_set(path_to_images=path_to_images, path_to_csv=path_to_csv)"
      ],
      "metadata": {
        "id": "qgDNIJNYJRhI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functional Model"
      ],
      "metadata": {
        "id": "1vzTuVg-KLfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Input, Dense, MaxPool2D, BatchNormalization, GlobalAvgPool2D, Flatten\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "def streesigns_model(nbr_classes):\n",
        "\n",
        "    my_input = Input(shape=(60,60,3))\n",
        "\n",
        "    x = Conv2D(32, (3,3), activation='relu')(my_input)\n",
        "    x = MaxPool2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "    x = MaxPool2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Conv2D(128, (3,3), activation='relu')(x)\n",
        "    x = MaxPool2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # x = Flatten()(x)\n",
        "    x = GlobalAvgPool2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(nbr_classes, activation='softmax')(x)\n",
        "\n",
        "    return Model(inputs=my_input, outputs=x)"
      ],
      "metadata": {
        "id": "8QyJVIRSKIj5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Generator\n",
        "**Generators are responsible to set structure for labels. This dataset is now categorized into folders. But there are no labels. Data generator takes care of this. It can take the folder structure and prepare for model training without generating label array.**"
      ],
      "metadata": {
        "id": "aX4m815vQd6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def create_generators(batch_size, train_data_path, val_data_path, test_data_path):\n",
        "\n",
        "    train_preprocessor = ImageDataGenerator(\n",
        "        rescale = 1 / 255.,\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.1\n",
        "    )\n",
        "\n",
        "    test_preprocessor = ImageDataGenerator(\n",
        "        rescale = 1 / 255.,\n",
        "    )\n",
        "\n",
        "    train_generator = train_preprocessor.flow_from_directory(\n",
        "        train_data_path,\n",
        "        class_mode=\"categorical\",\n",
        "        target_size=(60,60),\n",
        "        color_mode='rgb',\n",
        "        shuffle=True,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    val_generator = test_preprocessor.flow_from_directory(\n",
        "        val_data_path,\n",
        "        class_mode=\"categorical\",\n",
        "        target_size=(60,60),\n",
        "        color_mode=\"rgb\",\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    test_generator = test_preprocessor.flow_from_directory(\n",
        "        test_data_path,\n",
        "        class_mode=\"categorical\",\n",
        "        target_size=(60,60),\n",
        "        color_mode=\"rgb\",\n",
        "        shuffle=False,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    return train_generator, val_generator, test_generator"
      ],
      "metadata": {
        "id": "B5javJQhQgx4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_train = '/content/dataset/training_data_split/train'\n",
        "path_to_val = '/content/dataset/training_data_split/val'\n",
        "path_to_test = '/content/dataset/Test'\n",
        "batch_size = 64\n",
        "\n",
        "train_generator, val_generator, test_generator = create_generators(batch_size=batch_size, train_data_path=path_to_train, val_data_path=path_to_val,\n",
        "                  test_data_path=path_to_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgqZkkEPR5Fk",
        "outputId": "252214b6-6ef7-4083-ea5c-116e244dfc9c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 35288 images belonging to 43 classes.\n",
            "Found 3921 images belonging to 43 classes.\n",
            "Found 12630 images belonging to 43 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "path_to_save_model = '/content/Models'\n",
        "ckpt_saver = ModelCheckpoint(\n",
        "    path_to_save_model,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode='max',\n",
        "    save_best_only=True,\n",
        "    save_freq='epoch',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=10)\n",
        "\n",
        "nbr_classes = train_generator.num_classes\n",
        "epochs = 1\n",
        "\n",
        "model = streesigns_model(nbr_classes)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_generator,\n",
        "          epochs=epochs,\n",
        "          batch_size=batch_size,\n",
        "          validation_data=val_generator,\n",
        "          callbacks=[ckpt_saver, early_stop]\n",
        "          )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJZW3CTuTBo1",
        "outputId": "8c0a3d09-e5af-438a-aed6-29edef2ad312"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "552/552 [==============================] - ETA: 0s - loss: 1.6038 - accuracy: 0.5409\n",
            "Epoch 1: val_accuracy improved from -inf to 0.18490, saving model to /content/Models\n",
            "INFO:tensorflow:Assets written to: /content/Models/assets\n",
            "552/552 [==============================] - 61s 92ms/step - loss: 1.6038 - accuracy: 0.5409 - val_loss: 3.5193 - val_accuracy: 0.1849\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5c8421f490>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "rec004HeUImM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}